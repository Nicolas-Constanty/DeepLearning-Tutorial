{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Neural Network *aka Multilayered perceptron*\n",
    "\n",
    "The goal of this exercise is to build your own neural network from scratch and train it to recognise a series of handwritten digits. See *[The Perceptron](https://github.com/Claudiooo/DeepLearningLearning/blob/Group2/Jupyter/Nicolas/Perceptron.ipynb)* for more informations about **the perceptron concept**\n",
    "\n",
    "![Multilayered perceptron](https://raw.githubusercontent.com/Claudiooo/DeepLearningLearning/Group2/Images/mlp-network.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.3\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "print(np.version.version)\n",
    "import scipy.special\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading and formating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_number(file, size):\n",
    "    return int.from_bytes(file.read(size), byteorder='big', signed=False)\n",
    "\n",
    "def get_label_data(filename, number_label, offset):\n",
    "    file = open(filename, 'rb')\n",
    "    magix_number = (0x00000801).to_bytes(4, byteorder='big')\n",
    "    read_value = file.read(4)\n",
    "    if (read_value != magix_number):\n",
    "        print(\"This isn't a label file!\")\n",
    "        return 0\n",
    "    number_of_items = read_number(file, 4)\n",
    "    data = []\n",
    "    if (offset >= number_of_items):\n",
    "        return [number_of_items, 0]\n",
    "    if (number_label + offset > number_of_items):\n",
    "        number_label = number_of_items - offset\n",
    "    header_size = 8\n",
    "    file.seek(header_size + offset * number_label)\n",
    "    for i in range(number_label):\n",
    "        data.append(read_number(file, 1))\n",
    "    return [number_of_items, data]\n",
    "\n",
    "def normalise_number(number, minimum, maximum):\n",
    "    return (number - minimum) / (maximum - minimum)\n",
    "\n",
    "def get_image_data(filename, number_images, offset):\n",
    "    file = open(filename, 'rb')\n",
    "    magix_number = (0x00000803).to_bytes(4, byteorder='big')\n",
    "    read_value = file.read(4)\n",
    "    if (read_value != magix_number):\n",
    "        print(\"This isn't an image file!\")\n",
    "        return 0\n",
    "    number_of_items = read_number(file, 4)\n",
    "    number_of_rows = read_number(file, 4)\n",
    "    number_of_columns = read_number(file, 4)\n",
    "    if (offset >= number_of_items):\n",
    "        return [number_of_items, number_of_rows, number_of_columns, 0]\n",
    "    if (number_images + offset > number_of_items):\n",
    "        number_images = number_of_items - offset\n",
    "    data = []\n",
    "    minimum = 0.0\n",
    "    maximum = 255.0\n",
    "    image_size = number_of_rows * number_of_columns\n",
    "    header_size = 16\n",
    "    file.seek(header_size + image_size * offset)\n",
    "    for i in range(number_images):\n",
    "        pixels = []\n",
    "        for j in range(image_size):\n",
    "            pixels.append(normalise_number(read_number(file, 1), minimum, maximum))\n",
    "        data.append(pixels)\n",
    "    return [number_of_items, number_of_rows, number_of_columns, data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, inputnodes, hiddennodes, numberhiddenlayer, outputnodes, learning_rate):\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddennodes\n",
    "        self.nlayer = numberhiddenlayer\n",
    "        self.onodes = outputnodes\n",
    "        self.lr = learning_rate\n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)\n",
    "        #input to first hidden weight\n",
    "        self.hlayers = []\n",
    "        #create hidden layer\n",
    "        for i in range(self.nlayer + 1):\n",
    "            if (i == 0):\n",
    "                self.hlayers.append(np.random.normal(0.0, pow(self.inodes, -0.5), (self.hnodes, self.inodes)))\n",
    "                print(\"wih\", self.inodes, \"->\", self.hnodes)\n",
    "            elif (i + 1 == self.nlayer + 1):\n",
    "                self.hlayers.append(np.random.normal(0.0, pow(self.hnodes, -0.5), (self.onodes, self.hnodes)))\n",
    "                print(\"who\", self.hnodes, \"->\", self.onodes)\n",
    "            else:\n",
    "                self.hlayers.append(np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.hnodes)))\n",
    "                print(\"hidden\", self.hnodes)\n",
    "        self.last = len(self.hlayers) - 1\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        hidden_outputs = []\n",
    "        hidden_inputs = []\n",
    "        size = len(self.hlayers)\n",
    "        for i in range(size):\n",
    "            if (i == 0):\n",
    "                hidden_inputs.append(np.dot(self.hlayers[i], inputs))\n",
    "            else:\n",
    "                hidden_inputs.append(np.dot(self.hlayers[i], hidden_outputs[-1]))\n",
    "            hidden_outputs.append(self.activation_function(hidden_inputs[-1]))\n",
    "        \n",
    "        hidden_errors = None\n",
    "        output_errors = targets - hidden_outputs[size -1]\n",
    "        for i in range(size -1, -1, -1):\n",
    "            if (i == size - 1):\n",
    "#                 print(\"yo\")\n",
    "                hidden_errors = np.dot(self.hlayers[i].T, output_errors)\n",
    "                self.hlayers[i] += self.lr * np.dot((output_errors * hidden_outputs[i] * (1.0 - hidden_outputs[i])), np.transpose(hidden_outputs[i - 1]))\n",
    "            elif (i != 0):\n",
    "                output_errors = targets - hidden_outputs[i]\n",
    "#                 print(\"nop\")\n",
    "                # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "                hidden_errors = np.dot(self.hlayers[i].T, output_errors)\n",
    "                self.hlayers[i] += self.lr * np.dot((output_errors * hidden_outputs[i] * (1.0 - hidden_outputs[i])), np.transpose(hidden_outputs[i - 1]))\n",
    "            else:\n",
    "#                 print(\"yay\")\n",
    "                self.hlayers[i] += self.lr * np.dot((hidden_errors * hidden_outputs[i] * (1.0 - hidden_outputs[i])), np.transpose(inputs))\n",
    "            targets = hidden_errors\n",
    "        \n",
    "    def query(self, inputs_list):\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        hidden_outputs = []\n",
    "        hidden_inputs = []\n",
    "        size = len(self.hlayers)\n",
    "        for i in range(size):\n",
    "            if (i == 0):\n",
    "                hidden_inputs.append(np.dot(self.hlayers[i], inputs))\n",
    "            else:\n",
    "                hidden_inputs.append(np.dot(self.hlayers[i], hidden_outputs[-1]))\n",
    "            hidden_outputs.append(self.activation_function(hidden_inputs[-1]))\n",
    "\n",
    "        return hidden_outputs[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Brain class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brain:\n",
    "    def __init__(self, nn):\n",
    "        self.nn = nn\n",
    "        self.total_iteration = 0\n",
    "        \n",
    "    def learn(self, data, label_data, number_iteration):\n",
    "        for i in range(number_iteration):\n",
    "            self.total_iteration += 1\n",
    "            for j in range(len(data)):\n",
    "                targets = np.zeros(nn.onodes) + 0.01\n",
    "                targets[label_data[j]] = 0.99\n",
    "                nn.train(data[j], targets)\n",
    "    \n",
    "    def recognise(self, data, label_data):\n",
    "        score = 0\n",
    "        for i in range(len(data)):\n",
    "            targets = np.zeros(nn.onodes) + 0.01\n",
    "            targets[label_data[i]] = 0.99\n",
    "            res = nn.query(data[i])\n",
    "#             print(res)\n",
    "            label = np.argmax(res)\n",
    "#             print(label)\n",
    "            if (label == label_data[i]):\n",
    "                score += 1\n",
    "        return score / float(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wih 784 -> 200\n",
      "hidden 200\n",
      "who 200 -> 10\n",
      "After  0  iteration :\n",
      "Success :  9.82 %\n",
      "After  1  iteration :\n",
      "Success :  91.24 %\n",
      "After  2  iteration :\n",
      "Success :  92.24 %\n",
      "After  3  iteration :\n",
      "Success :  92.84 %\n",
      "After  4  iteration :\n",
      "Success :  93.5 %\n",
      "After  5  iteration :\n",
      "Success :  90.86999999999999 %\n",
      "After  6  iteration :\n",
      "Success :  93.41000000000001 %\n",
      "After  7  iteration :\n",
      "Success :  93.82000000000001 %\n",
      "After  8  iteration :\n",
      "Success :  94.32000000000001 %\n",
      "After  9  iteration :\n",
      "Success :  93.69 %\n",
      "After  10  iteration :\n",
      "Success :  94.17 %\n",
      "Execution time :  736.5199599266052  secondes\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    image_data = get_image_data(\"train-images.idx3-ubyte\", 60000, 0)\n",
    "    label_data = get_label_data(\"train-labels.idx1-ubyte\", 60000, 0)\n",
    "    nn = NeuralNetwork(image_data[1] * image_data[2], 200, 2, 10, 0.1)\n",
    "    brain = Brain(nn)\n",
    "#     print(label_data)\n",
    "#     print(image_data)\n",
    "    iteration = 10\n",
    "    image_test_data = get_image_data(\"t10k-images.idx3-ubyte\", 10000, 0)\n",
    "    label_test_data = get_label_data(\"t10k-labels.idx1-ubyte\", 10000, 0)\n",
    "    print(\"After \", 0, \" iteration :\")\n",
    "    print(\"Success : \", brain.recognise(image_test_data[3], label_test_data[1]) * 100, \"%\")\n",
    "    start_time = time.time()\n",
    "    for i in range(iteration):\n",
    "        brain.learn(image_data[3], label_data[1], 1)\n",
    "        print(\"After \", i + 1, \" iteration :\")\n",
    "        print(\"Success : \", brain.recognise(image_test_data[3], label_test_data[1]) * 100, \"%\")\n",
    "    print(\"Execution time : \", time.time() - start_time, \" secondes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links\n",
    "\n",
    "#### Youtube\n",
    " * [The Coding Train - 10.4: Neural Networks: Multilayer Perceptron Part 1](https://www.youtube.com/watch?v=u5GAVdLQyIg&list=PLRqwX-V7Uu6aCibgK1PTWWu9by6XFdCfh&index=4)\n",
    " * [The Coding Train - 10.4: Neural Networks: Multilayer Perceptron Part 2](https://www.youtube.com/watch?v=IlmNhFxre0w&list=PLRqwX-V7Uu6aCibgK1PTWWu9by6XFdCfh&index=5)\n",
    " * [3Blue1Brown - But what \\*is* a Neural Network? | Deep learning, chapter 1](https://www.youtube.com/watch?v=aircAruvnKk)\n",
    " * [3Blue1Brown - Gradient descent, how neural networks learn | Deep learning, chapter 2\n",
    "](https://www.youtube.com/watch?v=IHZwWFHWa-w)\n",
    "\n",
    "#### Web\n",
    " * [Wikipedia - Multilayered perceptron](https://www.wikiwand.com/en/Multilayer_perceptron)\n",
    " \n",
    "#### Data\n",
    " * [THE MNIST DATABASE of handwritten digits](http://yann.lecun.com/exdb/mnist/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
